[
  {
    "objectID": "objectsinspace.html",
    "href": "objectsinspace.html",
    "title": "Annual Number of Objects Launched In Outer Space",
    "section": "",
    "text": "Here, my graph shows the number of objects launched into space from 1960 until present day. Credit goes to Our World in Data and the United Nations Office for Outer Space Affairs since 1962."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "test test test"
  },
  {
    "objectID": "ethics.html",
    "href": "ethics.html",
    "title": "Amazon and Times Article Ethics",
    "section": "",
    "text": "With these two articles being written in 2018 and 2020, it is clear that data-driven tools have been adopted in multiple pertinent areas of society like hiring and policing in the name of efficiency, especially since machine learning was at a time of high growth in this time due to “a surge in low-cost computing power”. Unfortunately, creating these tools in the name of efficiency can appear appealing to companies due to the vast amount of computing power that algorithms can complete in a short amount of time. However, at the same time, these same individuals adapting these policies overlook other significant factors, such as amplified bias and real-world harm. Specifically, this is in regards to Reuter’s article from 2018 with Amazon’s secret AI recruiting tool which ended up showing bias against women, as well as a Times article in 2020 where Robert Williams Williams (2024) was wrongfully arrested due to a false target by a law enforcement algorithmic tool with a faulty facial recognition match. \nIn the Amazon Dastin (2018), the company built an AI tool to speed up the hiring process by designating AI to score resumes on a five-star scale, with this eventually ending up penalizing resumes which included words related to “woman”. This is because the model was trained based on Amazon resumes which were submitted over the last 10 years, most of which came from men due to the gender imbalance in tech. This resulted in increased discovery of how data that is biased in training can result in discriminatory decisions with real-world negative impacts; and although this tool was eventually shut down, it raises the ethical concerns of solely relying on AI in hiring decisions. Further, in the Times Williams (2024) article, Robert Williams recounts the trauma his family faced after he was dragged out by police officers due to a faulty facial recognition match despite him having no connection to the alleged crime. Williams’ expired driver’s license was matched to blurry security footage, with this being the basis for which law enforcement decided to arrest Williams in front of his family. This is an additional testimony in which sole reliance on poorly-trained algorithms can have extreme negative consequences that are difficult to overturn, directly impacting marginalized communities the most. In both of these cases, the unchecked use of machine learning resulted in the perpetuation of systemic inequities thus increasing the necessity for data science tools created with accountability.\nIn terms of consent structures for recruiting participants, although the participants may have potentially signed some sneaky Terms and Conditions, the data ultimately was used without informed and clear permissions from the individuals affected. Amazon Dastin (2018) used prior resumes from job applicants to train their AI model which ended up being biased against women and ultimately disenfranchising their hiring process, without explicitly informing applicants that their data would be used to train a model. In Robert William’s case, the use of his expired driver’s license photo from a state database to identify him without his consent did lack explicit content. Now, this is to say that there’s no way someone who is potentially guilty of a crime would ever agree to an algorithm that would ultimately identify them as a perpetrator to a crime. But, the issue at hand is whether anyone who is guilty or not should be subject to surveillance or judgment by an algorithm without clear and informed consent. This is why consent is based upon the pillars of accountability and transparency, and in both of the contexts of our article there is an absence of how individual data was used resulting in unchecked systemic discrimination.\nThis leads in to the fact that the data used was in fact identifiable, with the Amazon resume AI model being trained off of real resumes with education history, affiliations, and names, ultimately learning to penalize the achievements of women that the model would come across. Robert William’s situation resulted in his personal facial technology being used to pinpoint him in a case he was not at all complicit in, with his facial features being highly personal biometric data. In the case of Amazon Dastin (2018), the data was not anonymized to the extent it should have been since the AI tool ended up learning how to discriminate and infer gender. With Williams, there is no irreversibility to facial recognition, thus highlighting the need for proper oversight and safeguards for personal biometric data.\nIn the case of who was measured, Amazon Dastin (2018) trained its models based on past resumes presumably for its engineering-related positions; which unfortunately are roles predominantly occupied by men. Due to this oversight in the training process, the AI model repeatedly seeing resumes by males must have made it assume that these resumes are somehow “superior” and began to associate male candidates as being rated higher. This becomes problematic since Amazon’s mission of hiring a diverse range of candidates was not met here since they likely used resumes majority held by men for their model, with this not being representative of the people we’d like to generalize to the algorithm. This makes it difficult to assess the ethics of analyzing data for which the implications of its use are not fully understood, especially since the lack of this consideration can perpetuate biases they aim to reduce.\nIn terms of race and gender being used as a variable, while these variables were not explicitly mentioned in the training models, they ended up playing a major role in the outcomes of the algorithms due to false training data. Amazon’s AI tool inferred the resumes of males to be related to higher quality, and the false identification of Williams is testament to the frequency of which facial recognition systems unfortunately misclassify Black individuals. These factors were not acknowledged presumably in the initial training process, but ended up in discriminatory results. These two examples show how identities can be turned into inherent statistical disadvantages that show how race can result in how likely how someone can be misidentified, and gender-related affiliations were proxes for someone’s gender and how worthy of a candidate they were for the resume rating.\nDastin (2018)\nWilliams (2024)\n\n\n\n\nReferences\n\nDastin, Jeffrey. 2018. “Amazon Scraps Secret AI Recruiting Tool That Showed Bias Against Women.” 2018. https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G.\n\n\nWilliams, Robert. 2024. “I Was Wrongfully Arrested Because of Facial Recognition Technology. It Shouldn’t Happen to Anyone Else.” 2024. https://time.com/6991818/wrongfully-arrested-facial-recognition-technology-essay/."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Frank’s Website",
    "section": "",
    "text": "Github Repo: https://github.com/frankilicious1/frankilicious1.github.io.git"
  },
  {
    "objectID": "postoffice.html",
    "href": "postoffice.html",
    "title": "Post Office Development Permutation Test",
    "section": "",
    "text": "The data for this project of post offices that operated in the United States between 1639-2000 comes from Cameron Blevins and Richard W. Helbock in the Harvard Dataverse. For this project, I chose the first option which is conducting a permutation test by simulator behavior under the null hypothesis. Specifically, I sought to see whether the average number of post offices established on a per decade basis has decreased in recent years, specifically before 1900 compared to after 1900 until 2000.\nThis dataset provides context for how many post offices were implemented yearly since the birth of the U.S. I mutated another variable into established decade in order to group the amount of post offices built into a decade basis for easier visualization. Then, this data is grouped into an early time period which is before 1900 and then after 1900 which would be considered modern time.\nAcknowledging the critical role post offices played in the development of the U.S., it is fascinating to visualize and interpret this data to see how the priority of post offices for vital communication and shipping may have changed in the past centuries. This is especially so since this data allows visualization of U.S. infrastructure growth in recent years as well as U.S. westward expansion.\n\n\n\n\n\n\n\n\n\nIn the plot above, we see the number of post offices built from 1800 to 2000. There is a clear surge in the 1800s with this number eventually dwindling down, fueling the hypothesis for this project since there may have been more of an emphasis in post offices in the 1800s.\n\n\n# A tibble: 6 × 3\n  est_decade     n period\n       &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; \n1       1800  1436 early \n2       1810  2503 early \n3       1820  5944 early \n4       1830  8480 early \n5       1840  7829 early \n6       1850 16271 early \n\n\n[1] 9990.764\n\n\n\n\n\n\n\n\n\n[1] 0.005\n\n\nIn this histogram running our permutation test, we observe the null distribution of the difference in average post offices per decade between early and modern periods. This assumes “early” and “modern” have no real effect under the null hypothesis. Each bar is one of 1,000 simulated differences after the labels had been randomly shuffled.\nThe red dashed value is our observed value is quite far to the right, suggesting that a drastic difference is not likely just because of chance. This provides evidence for our hypothesis that the early period of the U.S. before 1900 had much more post office development than the modern period. This makes sense since U.S. historical expansion was quite concentrated in the 1800s as westward expansion was in its prime as well as the U.S. government attempting to spread out its infrastructure. mean(null_diffs &gt;= obs_diff)\nThe p-value being 0.005 means only 0.5% of the permuted differences were as large as the observed ones, rejecting the null hypothesis. This supports that the pre-1900s saw more growth in post offices than the modern period. This is an interesting glimpse into the early development of the United States and how the value of post offices may have shifted over the history of our country as well our priorities as a society."
  },
  {
    "objectID": "trafficsql.html",
    "href": "trafficsql.html",
    "title": "Traffic Data SQL",
    "section": "",
    "text": "Introduction\nThis SQL wrangling analysis focuses on the Stanford Open Policing Project Pierson et al. (2020) which standardizes data on vehicle and pedestrian spots from law enforcement across the country in order to combine statistical analysis and data journalism. My project focuses on the data from Charlotte, Chicago, and New Orleans, with this data coming from the Stanford Open Policing Project published by Pierson et al. (2020). Pierson et al. (2020) All of the data is from 2020 but Chicago’s is specifically from 2023. The population sizes of the cities do vary since Charlotte has approximately 900,000 individuals, Chicago having 2.6 million, and New Orleans having 364,000. While this may seem unusual to analyze cities in such different populations, I wanted to have a city of a small, medium, and large caliber so that the metric used of search rate per stop controls for total stop volume.\nThis bar chart compares the search rate by age group across Charlotte, Chicago, and New Orleans.\n\n\n\n\n\n\n\n\n\nNew Orleans stands out as having the highest search rates among all age demographics, especially for drivers under 30 with the rate being around 0.2 for minors and just above 0.15 for adults under 30. Charlotte has search rates that are a bit more moderate and declining with age, while Chicago’s search rates remain much lower regardless of age. Some reasons for New Orleans have such high search rates may be due to reports of the city over policing its communities. Even though the height of this controversy was in 2013, the remnants of this may still remain. Chicago may have placed more reforms for its policing efforts, especially since its 2014 case with Laquan McDonald sparked controversy in communities. Chicago may have shifted their policing more towards data-driven policing or citation based enforcement so there aren’t as many physical searches. In addition, training methods in police departments across the U.S. may vary extensively which can account for Chicago’s low search rates regardless of age group.\n\n\n\n\n\n\n\n\n\nThe arrest rates tell quite a story here across the cities of Charlotte, Chicago, and New Orleans. New Orleans has a massively higher arrest rate for minors with it being at almost 28%. Chicago has high arrests for adults 18-45 with them being almost at 20%. Despite Chicago having low search rates, stops likely escalate to arrests. Charlotte consistently across age groups has lower arrest rates, with this indicating extreme variance in how these cities approach policing. The 28% arrest rate for minors in New Orleans is a bit alarming because of overcriminalization in youth and how this may shape their future having a record. This is why understanding the factors of policing is critical to ensuring healthy communities that are functional.\n\n\n\n5 records\n\n\nage_group\ntotal_stops\nsearch_rate\narrest_rate\n\n\n\n\n&lt;18\n22252\n0.0986\n0.0436\n\n\n18–30\n736017\n0.0799\n0.0426\n\n\n31–45\n562977\n0.0441\n0.0306\n\n\n46–60\n228302\n0.0288\n0.0208\n\n\n60+\n48898\n0.0096\n0.0068\n\n\n\n\n\nIn Charlotte’s situation, search rates and arrest rates decline with wage. These rates are in the medium ratio compared to Chicago and New Orleans. There is an arrest rate that is highest with minors and younger adults, lining up with other relationships. There is a clear age-related disparity in enforcement, especially since senior citizens have less than 1% of search and arrest rates based on total stops.\n\n\n\n5 records\n\n\nage_group\ntotal_stops\nsearch_rate\narrest_rate\n\n\n\n\n&lt;18\n7970\n0.0153\n0.0033\n\n\n18–30\n609351\n0.0122\n0.1762\n\n\n31–45\n502562\n0.0071\n0.1505\n\n\n46–60\n259737\n0.0035\n0.0996\n\n\n60+\n91455\n0.0018\n0.0361\n\n\n\n\n\nChicago has the lowest search rates with them never exceeding 1.53%. However, something that is interesting to note here is that even though 1% of individuals aged 18-30 are searched, over 17% are arrested. This may be due to stops being more warranted in Chicago, meaning they may be due to warrants or other severe violations that are not related to trivial stops like speeding.\n\n\n\n5 records\n\n\nage_group\ntotal_stops\nsearch_rate\narrest_rate\n\n\n\n\n&lt;18\n18487\n0.2106\n0.2801\n\n\n18–30\n220256\n0.1612\n0.1926\n\n\n31–45\n150491\n0.1543\n0.1930\n\n\n46–60\n90071\n0.1253\n0.1656\n\n\n60+\n20001\n0.0613\n0.0906\n\n\n\n\n\nNew Orleans by far has the highest arrest rates, with minors being arrested in 28% of total stops. Search rates are also quite high for young drivers with the rate being at 21%. There may be even less of an age-related disparity in New Orleans since their arrest rates for individuals 60+ are 9% and search rates 6%, suggesting a much stricter enforcement-based approach irrespective of age. This heavy policing in youth may be due to a lack of policies helping teenagers with their time like cocurricular and extracurricular programming funded by the city. In addition, law enforcement may bias younger individuals as more likely to be reckless, associating them with trouble which is common in overpoliced communities.\nOverall, our data shows that youth under 30 are under high scrutiny by police, especially in New Orleans with its high search and arrest rates. In Chicago, the data is quite interesting since it presents rare searches but high arrests. This may reflect a difference in philosophy of the respective cities policing. The consequences are quite real especially since youth in New Orleans are arrested in nearly one-third of stops, a reality that may shape their access to education and employment for years. Understanding policing trends and pairing them with research is essential to safeguard communities.\n\n\n\n\n\n\nReferences\n\nPierson, Emma, Camelia Simoiu, Jan Overgoor, Sam Corbett-Davies, Daniel Jenson, Amy Shoemaker, Vignesh Ramachandran, and Sharad Goel. 2020. “A Large-Scale Analysis of Racial Disparities in Police Stops Across the United States.” Nature Human Behaviour, 1–10."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi there, my name is Frank and I am currently a sophomore at Pomona College! I was raised in Chicago but originally was born in Poland. I enjoy hiking, visiting new places, biking, and finding new TV shows to binge. Currently, my favorite show to watch is Sex and the City!"
  },
  {
    "objectID": "finalpres.html#project-1---objects-launched-into-space",
    "href": "finalpres.html#project-1---objects-launched-into-space",
    "title": "Final Presentation",
    "section": "Project 1 - Objects Launched Into Space",
    "text": "Project 1 - Objects Launched Into Space\n\nOverview\n\n\n\nTwo TidyTuesday datasets\nData on the total number of flights per month (2010-2018)\nData on the change in CO2 emission\n\n\n\n\nOverview\n\nMeow Meow\nMeow meow\n\nCode Visualization"
  },
  {
    "objectID": "finalpres.html#project-1-objects-launched-into-space",
    "href": "finalpres.html#project-1-objects-launched-into-space",
    "title": "Final Presentation",
    "section": "Project 1 – Objects Launched Into Space",
    "text": "Project 1 – Objects Launched Into Space\n\nOverviewCode Visualization\n\n\n\nTwo TidyTuesday datasets\n\nData on the total number of flights per month (2010–2018)\n\nData on the change in CO2 emission\n\n\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(readr)\n\nouter_space_objects &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-04-23/outer_space_objects.csv')\n\nlaunches_per_year &lt;- outer_space_objects %&gt;%\n  group_by(Year) %&gt;%\n  summarize(total_objects = sum(num_objects, na.rm = TRUE)) %&gt;%\n  arrange(Year)\n\nmax_launch_year &lt;- launches_per_year %&gt;%\n  filter(total_objects == max(total_objects))\n\nggplot(launches_per_year, aes(x = Year, y = total_objects)) +\n  geom_line(color = \"blue\") +\n  geom_point(alpha = 0.2) +\n  geom_text(aes(label = ifelse(total_objects == max(total_objects), \n                               paste0(total_objects, \" launches\"), \"\"))) +\n  labs(title = \"Trend of Space Object Launches by Year\",\n       x = \"Year\",\n       y = \"Number of Objects Launched\") +\n  theme_minimal()"
  },
  {
    "objectID": "finalpres.html#project-2-traffic-stops-by-age-group",
    "href": "finalpres.html#project-2-traffic-stops-by-age-group",
    "title": "Final Presentation",
    "section": "Project 2 – Traffic Stops by Age Group",
    "text": "Project 2 – Traffic Stops by Age Group\n\nOverviewSearch Rate by AgeArrest Rate by Age\n\n\n\nUsing the Stanford Open Policing Project\n\nComparing Charlotte, Chicago, and New Orleans\n\nFocused on age-based disparities in search and arrest rates\n\nAll data from 2020 (except Chicago: 2023)\n\n\n\n\nlibrary(ggplot2)\n\nggplot(age_data, aes(x = age_group, y = search_rate, fill = city)) +\n  geom_col(position = \"dodge\") +\n  labs(\n    title = \"Search Rate by Age Group\",\n    x = \"Age Group\",\n    y = \"Search Rate\",\n    fill = \"City\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nggplot(arrest_data, aes(x = age_group, y = arrest_rate, fill = city)) +\n  geom_col(position = \"dodge\") +\n  labs(\n    title = \"Arrest Rate by Age Group\",\n    x = \"Age Group\",\n    y = \"Arrest Rate\",\n    fill = \"City\"\n  )"
  },
  {
    "objectID": "finalpres.html#project-5-traffic-stops-by-age-group",
    "href": "finalpres.html#project-5-traffic-stops-by-age-group",
    "title": "Final Presentation",
    "section": "Project 5 – Traffic Stops by Age Group",
    "text": "Project 5 – Traffic Stops by Age Group\nOverview\n\nUsing the Stanford Open Policing Project\n\nComparing Charlotte, Chicago, and New Orleans\n\nFocused on age-based disparities in search and arrest rates\n\nSearch Rate by Age\n\nNew Orleans has the highest search rates across all age groups\nYoung drivers (under 30) face the most frequent searches\nCharlotte has moderate search rates that decline with age\nChicago has consistently low search rates regardless of age\n\n\nlibrary(ggplot2)\n\nggplot(age_data, aes(x = age_group, y = search_rate, fill = city)) +\n  geom_col(position = \"dodge\") +\n  labs(\n    title = \"Search Rate by Age Group\",\n    x = \"Age Group\",\n    y = \"Search Rate\",\n    fill = \"City\"\n  )\n\n\n\n\n\n\n\n\nArrest Rate by Age\n\nMinors in New Orleans are arrested in nearly 28% of stops\nChicago shows high arrest rates for ages 18–45 despite low search rates\nArrest trends reveal major differences in how cities enforce stops by age\n\n\nggplot(arrest_data, aes(x = age_group, y = arrest_rate, fill = city)) +\n  geom_col(position = \"dodge\") +\n  labs(\n    title = \"Arrest Rate by Age Group\",\n    x = \"Age Group\",\n    y = \"Arrest Rate\",\n    fill = \"City\"\n  )"
  }
]